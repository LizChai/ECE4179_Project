{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9ea2915-6283-4a60-8b7f-71ebb59465c7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.10.2-py3-none-any.whl (2.8 MB)\n",
      "Requirement already satisfied: filelock in c:\\users\\ieliz\\appdata\\roaming\\python\\python38\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ieliz\\anaconda3\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ieliz\\anaconda3\\lib\\site-packages (from transformers) (1.20.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\ieliz\\anaconda3\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ieliz\\anaconda3\\lib\\site-packages (from transformers) (2021.4.4)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\ieliz\\anaconda3\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Collecting huggingface-hub>=0.0.12\n",
      "  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp38-cp38-win_amd64.whl (2.0 MB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ieliz\\anaconda3\\lib\\site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ieliz\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\ieliz\\anaconda3\\lib\\site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\ieliz\\anaconda3\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\ieliz\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ieliz\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ieliz\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: joblib in c:\\users\\ieliz\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\ieliz\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in c:\\users\\ieliz\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.0.17 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.10.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084ccaf5-3cfc-4b04-9a88-1ef14abfcc75",
   "metadata": {},
   "source": [
    "# Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30db8af7-09a9-4ce0-8c98-8a31f275ca44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import GPT2LMHeadModel , GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f4382c-4b8f-40ee-94a7-b9edb6cbcd5f",
   "metadata": {},
   "source": [
    "# Download tokens and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c32b0b6-e4a2-4c64-a190-ba49f4fe6c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3607f49797dd43b1a1d0e95b50084012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc31d567985f457aa042d5bb25698cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8bcda94b9c44953b606e8b4b2c83b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9757bc7b3b3447198ab51d90c0beffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/666 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9fec1d75ef34e3eb4f6e4e3cd396dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-large') \n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2-large', pad_token_id = tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f68283-7b5c-48a3-bbbf-c1e0fcacb183",
   "metadata": {},
   "source": [
    "# Test encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "152110f0-00d0-4742-8cc9-5a929f96412a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 464, 6193,  318, 3621]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode text and return torch tensors 'pt' (PyTorch tensors)\n",
    "# Converts words into numbers (indices)\n",
    "topic = \"The weather is nice\"\n",
    "input_ids = tokenizer.encode(topic, return_tensors = 'pt')\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72938db0-bfb6-4c05-a58b-d4a6930386ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The weather is nice'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode text from indices\n",
    "tokenizer.decode(input_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e400ddcd-7df1-4411-b2c8-182589e99fc0",
   "metadata": {},
   "source": [
    "# Generate text "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb79f89f-6ead-4921-9313-0d56b2016cd0",
   "metadata": {},
   "source": [
    "## Beam Search generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3847e8b0-5aa3-4d26-9efb-fe5fb1c29ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text using generate function from GPT2LMHeadModel via beam search\n",
    "# https://huggingface.co/blog/how-to-generate\n",
    "# Args: max_length: maximum number of words in generated text\n",
    "#       num_beams: beam search reduces risk of missing hidden high probability word sequences by keeping the most\n",
    "#                  likely num_beams of hypotheses at each time step and eventually choosing the hypothesis that has \n",
    "#                  the overall highest probability\n",
    "#       no_repeat_ngram_size: while result is arguably more fluent, output still includes repetition of same word seqs\n",
    "#                  introduce n-grams (word seqs of n words) penalties\n",
    "output_beam = model.generate(input_ids, max_length = 500, num_beams = 5, \n",
    "                        no_repeat_ngram_size  = 2, early_stopping = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d320bc5-fe40-4285-89f0-04a9682cd50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(output_beam[0], skip_special_tokens = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab322c6-418a-4518-bc51-2bcca8004b11",
   "metadata": {},
   "source": [
    "## Top-K sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478f3819-7001-473a-99ed-a74c77b39740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2b6874-8771-4c61-9292-968b8de91060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text using generate function from GPT2LMHeadModel via Top-K sampling\n",
    "# K most likely next words are filtered and probability mass is redistributed among only those K next words\n",
    "# Method adopted by GPT2\n",
    "output_topk = model.generate(input_ids, do_sample=True, max_length = 500, top_k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7eaff7-5cfb-4ef1-b039-eb5a9480a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(output_topk[0], skip_special_tokens = True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
